{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0604 Linear Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMtNLzlHgSvwdka77C0DSvK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeopjjang/ML-Study/blob/main/0604_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XoxDlRsO24E"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJgjVzhQRvR1"
      },
      "source": [
        "# Setting Data\n",
        "x_data = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "y_data = np.array([2.0, 4.0, 6.0 ,8.0 ,10.0])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j0i6vYwR5fO"
      },
      "source": [
        "w = np.random.uniform(0,10)\n",
        "b = np.random.uniform(0.10)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY6r1TCtFfAJ"
      },
      "source": [
        "y_pred = w * x_data + b"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ-ChvUISIx9"
      },
      "source": [
        "# Cost function\n",
        "def cost(x,y,w,b):\n",
        "  y_pred = w * x + b\n",
        "  cost = sum(pow(y_pred - y, 2))/len(y)\n",
        "  return cost"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4anujRnT_4N"
      },
      "source": [
        "# comupte gradient\n",
        "def grad_w(x,y,w,b):\n",
        "  return 2 * sum((w * x + b - y) * x)/len(y)\n",
        "\n",
        "def grad_b(x,y,w,b):\n",
        "  return 2 * sum(w * x + b - y)/len(y)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDNmQ9JOUkt8"
      },
      "source": [
        "def Training(x,y,epochs=100,lr=0.01):\n",
        "  w = np.random.uniform(0,10)\n",
        "  b = np.random.uniform(0.10)\n",
        "  for i in range(epochs):\n",
        "    g_w = grad_w(x,y,w,b)\n",
        "    g_b = grad_b(x,y,w,b)\n",
        "    w -= lr * g_w\n",
        "    b -= lr * g_b\n",
        "    c = cost(x,y,w,b)\n",
        "    if i%10 == 0 :\n",
        "      print(\"{:5} | {:10.4} | {:10.4} | {:10.6f}\".format(i,w,b,c))\n",
        "  return w, b"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ThiWt3iHpYz",
        "outputId": "127de5bb-d8f7-4719-cb3e-1e361641017b"
      },
      "source": [
        "Training(x_data,y_data)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |      5.468 |     0.1163 | 134.721880\n",
            "   10 |      2.428 |    -0.6974 |   0.712565\n",
            "   20 |      2.218 |    -0.7286 |   0.100463\n",
            "   30 |      2.197 |     -0.708 |   0.091329\n",
            "   40 |       2.19 |    -0.6847 |   0.085337\n",
            "   50 |      2.183 |    -0.6619 |   0.079748\n",
            "   60 |      2.177 |    -0.6399 |   0.074525\n",
            "   70 |      2.171 |    -0.6186 |   0.069644\n",
            "   80 |      2.166 |     -0.598 |   0.065083\n",
            "   90 |       2.16 |    -0.5781 |   0.060821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.1553057141202845, -0.5607029061793481)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_zD2IDxLv-x",
        "outputId": "0332633d-157a-408a-c8fa-27f0f768915b"
      },
      "source": [
        "train_w, train_b = Training(x_data, y_data, 1000, 0.01)\n",
        "print(train_w * 5 + train_b)\n",
        "print(train_w * 2.5 + train_b)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |      6.794 |     0.1145 | 256.159460\n",
            "   10 |      2.603 |     -1.006 |   1.372008\n",
            "   20 |      2.312 |     -1.048 |   0.207115\n",
            "   30 |      2.283 |     -1.018 |   0.188695\n",
            "   40 |      2.273 |    -0.9842 |   0.176316\n",
            "   50 |      2.264 |    -0.9514 |   0.164768\n",
            "   60 |      2.255 |    -0.9198 |   0.153978\n",
            "   70 |      2.246 |    -0.8891 |   0.143893\n",
            "   80 |      2.238 |    -0.8595 |   0.134470\n",
            "   90 |       2.23 |    -0.8309 |   0.125663\n",
            "  100 |      2.222 |    -0.8032 |   0.117433\n",
            "  110 |      2.215 |    -0.7765 |   0.109743\n",
            "  120 |      2.208 |    -0.7506 |   0.102555\n",
            "  130 |      2.201 |    -0.7256 |   0.095839\n",
            "  140 |      2.194 |    -0.7015 |   0.089562\n",
            "  150 |      2.188 |    -0.6781 |   0.083697\n",
            "  160 |      2.182 |    -0.6555 |   0.078216\n",
            "  170 |      2.176 |    -0.6337 |   0.073093\n",
            "  180 |       2.17 |    -0.6126 |   0.068306\n",
            "  190 |      2.164 |    -0.5922 |   0.063833\n",
            "  200 |      2.159 |    -0.5725 |   0.059652\n",
            "  210 |      2.153 |    -0.5534 |   0.055746\n",
            "  220 |      2.148 |     -0.535 |   0.052095\n",
            "  230 |      2.143 |    -0.5172 |   0.048683\n",
            "  240 |      2.138 |    -0.4999 |   0.045495\n",
            "  250 |      2.134 |    -0.4833 |   0.042515\n",
            "  260 |      2.129 |    -0.4672 |   0.039731\n",
            "  270 |      2.125 |    -0.4516 |   0.037129\n",
            "  280 |      2.121 |    -0.4366 |   0.034697\n",
            "  290 |      2.117 |    -0.4221 |   0.032425\n",
            "  300 |      2.113 |     -0.408 |   0.030301\n",
            "  310 |      2.109 |    -0.3944 |   0.028317\n",
            "  320 |      2.106 |    -0.3813 |   0.026462\n",
            "  330 |      2.102 |    -0.3686 |   0.024729\n",
            "  340 |      2.099 |    -0.3563 |   0.023110\n",
            "  350 |      2.095 |    -0.3445 |   0.021596\n",
            "  360 |      2.092 |     -0.333 |   0.020182\n",
            "  370 |      2.089 |    -0.3219 |   0.018860\n",
            "  380 |      2.086 |    -0.3112 |   0.017625\n",
            "  390 |      2.083 |    -0.3008 |   0.016471\n",
            "  400 |      2.081 |    -0.2908 |   0.015392\n",
            "  410 |      2.078 |    -0.2811 |   0.014384\n",
            "  420 |      2.075 |    -0.2718 |   0.013442\n",
            "  430 |      2.073 |    -0.2627 |   0.012562\n",
            "  440 |       2.07 |     -0.254 |   0.011739\n",
            "  450 |      2.068 |    -0.2455 |   0.010970\n",
            "  460 |      2.066 |    -0.2373 |   0.010252\n",
            "  470 |      2.064 |    -0.2294 |   0.009580\n",
            "  480 |      2.061 |    -0.2218 |   0.008953\n",
            "  490 |      2.059 |    -0.2144 |   0.008367\n",
            "  500 |      2.057 |    -0.2073 |   0.007819\n",
            "  510 |      2.055 |    -0.2004 |   0.007307\n",
            "  520 |      2.054 |    -0.1937 |   0.006828\n",
            "  530 |      2.052 |    -0.1872 |   0.006381\n",
            "  540 |       2.05 |     -0.181 |   0.005963\n",
            "  550 |      2.048 |     -0.175 |   0.005573\n",
            "  560 |      2.047 |    -0.1691 |   0.005208\n",
            "  570 |      2.045 |    -0.1635 |   0.004867\n",
            "  580 |      2.044 |    -0.1581 |   0.004548\n",
            "  590 |      2.042 |    -0.1528 |   0.004250\n",
            "  600 |      2.041 |    -0.1477 |   0.003972\n",
            "  610 |       2.04 |    -0.1428 |   0.003712\n",
            "  620 |      2.038 |     -0.138 |   0.003468\n",
            "  630 |      2.037 |    -0.1334 |   0.003241\n",
            "  640 |      2.036 |     -0.129 |   0.003029\n",
            "  650 |      2.035 |    -0.1247 |   0.002831\n",
            "  660 |      2.033 |    -0.1206 |   0.002645\n",
            "  670 |      2.032 |    -0.1165 |   0.002472\n",
            "  680 |      2.031 |    -0.1127 |   0.002310\n",
            "  690 |       2.03 |    -0.1089 |   0.002159\n",
            "  700 |      2.029 |    -0.1053 |   0.002017\n",
            "  710 |      2.028 |    -0.1018 |   0.001885\n",
            "  720 |      2.027 |   -0.09839 |   0.001762\n",
            "  730 |      2.026 |   -0.09511 |   0.001646\n",
            "  740 |      2.025 |   -0.09194 |   0.001539\n",
            "  750 |      2.025 |   -0.08888 |   0.001438\n",
            "  760 |      2.024 |   -0.08592 |   0.001344\n",
            "  770 |      2.023 |   -0.08306 |   0.001256\n",
            "  780 |      2.022 |   -0.08029 |   0.001173\n",
            "  790 |      2.021 |   -0.07762 |   0.001097\n",
            "  800 |      2.021 |   -0.07504 |   0.001025\n",
            "  810 |       2.02 |   -0.07254 |   0.000958\n",
            "  820 |      2.019 |   -0.07012 |   0.000895\n",
            "  830 |      2.019 |   -0.06779 |   0.000836\n",
            "  840 |      2.018 |   -0.06553 |   0.000782\n",
            "  850 |      2.018 |   -0.06335 |   0.000730\n",
            "  860 |      2.017 |   -0.06124 |   0.000683\n",
            "  870 |      2.016 |    -0.0592 |   0.000638\n",
            "  880 |      2.016 |   -0.05723 |   0.000596\n",
            "  890 |      2.015 |   -0.05532 |   0.000557\n",
            "  900 |      2.015 |   -0.05348 |   0.000521\n",
            "  910 |      2.014 |    -0.0517 |   0.000486\n",
            "  920 |      2.014 |   -0.04998 |   0.000455\n",
            "  930 |      2.013 |   -0.04831 |   0.000425\n",
            "  940 |      2.013 |    -0.0467 |   0.000397\n",
            "  950 |      2.013 |   -0.04515 |   0.000371\n",
            "  960 |      2.012 |   -0.04364 |   0.000347\n",
            "  970 |      2.012 |   -0.04219 |   0.000324\n",
            "  980 |      2.011 |   -0.04079 |   0.000303\n",
            "  990 |      2.011 |   -0.03943 |   0.000283\n",
            "10.014721142355691\n",
            "4.988238222302268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-biIW8JN0qJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}